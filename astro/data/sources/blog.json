[
  {
    "id": "blog:newby-voicemail",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2012-02-07T00:00:00.000Z",
    "title": "Newby Voicemail",
    "summary": "",
    "url": "/Blog/newby-voicemail/",
    "tags": [
      "voicemail"
    ],
    "content_html": "<p>My second day at a job in 2007 I showed up early.  I came in the unlocked front doors and I set off an insane alarm.  <!--more--> Strobe lights were in effect.  I left a voicemail for my boss that has become something of urban legend.  One of my coworkers posted it on his blog Caffeinatedcoder (which is no longer) and it got picked up by someone who blogs regularly at Microsoft.  It was associated with another urban legend story at MS about a new employee dinging the car of someone with the lastname Gates.</p>\n<p>The original CaffeineCoder post:</p>\n<p><img src=\"/assets/images/ione/i1first.png\" alt=\"the post\"></p>\n<p>The traceback from the Microsoft blog:</p>\n<p><img src=\"/assets/images/ione/ione-back2.png\" alt=\"backtrace\"></p>\n<p>I find the whole thing funny.  It is part of my history now.  Someday I may own up my second &#39;Internet Notorious&#39; moment.</p>\n"
  },
  {
    "id": "blog:reading-json-from-bash-with-python",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2012-05-28T00:00:00.000Z",
    "title": "Read JSON in Bash with Python",
    "summary": "",
    "url": "/Blog/reading-json-from-bash-with-python/",
    "tags": [
      "JSON",
      "Bash",
      "Python"
    ],
    "content_html": "<p>Getting JSON from a flat file in a shell script</p>\n<p>JSON is become a defacto serialization standard. Getting at the info in Bash is nice.</p>\n<p><code>cat /var/myfile</code></p>\n<pre><code class=\"language-json\">{&#39;this&#39;: &#39;you&#39;}\n</code></pre>\n<p>Create a script that can access this data</p>\n<pre><code class=\"language-bash\">#!/bin/bash\nset -e\nFILE=&#39;/var/file&#39;\nif [[ ! -a $FILE ]]; then\n    exit 0\nfi\ndict_value=`python -c &#39;import json, os; d=json.loads(open(&quot;/var/file&quot;).read()); print d[&quot;this&quot;]&#39;`\necho $dict_value\n</code></pre>\n<p>Run it as a command <code>./script.sh</code></p>\n<blockquote>\n<p>you</p>\n</blockquote>\n"
  },
  {
    "id": "blog:Cisco-Octets-to-Mbps",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2012-07-12T00:00:00.000Z",
    "title": "Convert Cisco Octets to Mbps",
    "summary": "",
    "url": "/Blog/Cisco-Octets-to-Mbps/",
    "tags": [
      "Cisco"
    ],
    "content_html": "<p>Depending on the type of counter you want to track you can use one of the two</p>\n<h1>SNMP following OIDs</h1>\n<p>&#39;64&#39; bit counter =&gt; oid =&gt; &#39;.1.3.6.1.2.1.31.1.1.1&#39;\n&#39;32&#39; bit counter =&gt; oid =&gt; &#39;.1.3.6.1.2.1.2.2&#39;</p>\n<h1>Example Readings</h1>\n<p>Sampe 1 Transferred octets; <code>28879519327687</code></p>\n<p>Sampe 2 Transferred octets (10 seconds later) <code>28879428276119</code></p>\n<p>That&#39;s 91051568 octets in 10 seconds.</p>\n<p>Divide by 10 for per second value: 9105156</p>\n<p>Multiply by 8 for bits: 72841248</p>\n<p>Divide by 1048576 for Mbps: 69</p>\n<pre><code class=\"language-python\">&gt;&gt;&gt; 28879519327687 - 28879428276119\n91051568\n&gt;&gt;&gt; 91051568 / 10 \n9105156\n&gt;&gt;&gt; 9105156 * 8\n72841248\n&gt;&gt;&gt; 72841248 / 1048576\n69\n</code></pre>\n<h1>Reference</h1>\n<p><a href=\"https://www.cisco.com/c/en/us/support/docs/ip/simple-network-management-protocol-snmp/8141-calculate-bandwidth-snmp.html\">How To Calculate Bandwidth Utilization Using SNMP</a>\n<a href=\"https://www.cisco.com/c/en/us/support/docs/ip/simple-network-management-protocol-snmp/26007-faq-snmpcounter.html\">Consider SNMP Counters: Frequently Asked Questions</a></p>\n"
  },
  {
    "id": "blog:motd-debian",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2012-07-21T00:00:00.000Z",
    "title": "Settings a modular MOTD in Debian",
    "summary": "",
    "url": "/Blog/motd-debian/",
    "tags": [
      "Debian"
    ],
    "content_html": "<p>Granular control over Debian MOTDMOTD should be used for more than welcome messages</p>\n<h1>What version am I on?</h1>\n<pre><code>cat /etc/issue\n\nDebian GNU/Linux 6.0 \\n \\l\n</code></pre>\n<h1>PAM has the ability to build a motd on demand</h1>\n<blockquote>\n<p>mkdir /etc/update-motd.d/\nnano /etc/update-motd.d/test</p>\n</blockquote>\n<pre><code class=\"language-bash\">#!/bin/bash\necho &#39;test&#39;\n</code></pre>\n<blockquote>\n<p>logout\nlogin</p>\n</blockquote>\n<pre><code>test\nme@vm:~$ \n</code></pre>\n<p>This way different teams can update the motd, and they can be ordered like 10test, 20test, 30test.</p>\n"
  },
  {
    "id": "blog:Basic-JSON-Python-REST-Client",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2012-07-24T00:00:00.000Z",
    "title": "Basic Python JSON REST API Client Example",
    "summary": "",
    "url": "/Blog/Basic-JSON-Python-REST-Client/",
    "tags": [
      "standard"
    ],
    "content_html": "<p>JSON REST API&#39;s are increasingly common and useful.</p>\n<p>A basic client example for using something like <a href=\"https://github.com/zorkian/nagios-api\">nagios api</a></p>\n<pre><code class=\"language-Python\">import sys\nimport os\nimport urllib\nimport json\nimport urllib2\n\nclass JSONRestClient(object):\n    def __init__(self, remote):\n        self.url = remote\n\n    def _get(self, trail):\n        getme = self.url + trail\n        req = urllib2.Request(getme)\n        return json.loads(urllib2.urlopen(req, timeout=120).read())\n\n    def _post(self, trail, **kwargs):\n        data = json.dumps(kwargs)\n        req = urllib2.Request(self.url + trail, data, {&#39;Content-Type&#39;: &#39;application/json&#39;})\n        f = urllib2.urlopen(req)\n        response = f.read()\n        f.close()\n        return json.loads(response)\n\n    def state(self):\n        return self._get(&#39;state&#39;)\n</code></pre>\n<h1>Getting state info from nagios api</h1>\n<p>r = JSONRestClient(&#39;<a href=\"http://remotehost:8080\">http://remotehost:8080</a>&#39;)\nprint r.state()</p>\n"
  },
  {
    "id": "blog:Python-Regex",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2012-08-02T00:00:00.000Z",
    "title": "Basic Python Regex Extraction",
    "summary": "",
    "url": "/Blog/Python-Regex/",
    "tags": [
      "Python",
      "Regex"
    ],
    "content_html": "<p>When dealing with totally unstructured data sometimes it is necessary to go full regex.</p>\n<p>Extracting values from a string using regex</p>\n<pre><code class=\"language-python\">import re\nstring = &#39;working on X000 for Y1111&#39;\n\ntag_matches = {&#39;x&#39;: &#39;X\\d{1,6}&#39;,\n               &#39;y&#39;: &#39;Y\\d{1,6}&#39;}\n\nfor k, v in tag_matches.iteritems():\n    title_search = re.search(v, string, re.IGNORECASE)\n    if title_search:\n        print k, title_search.group(0)\n</code></pre>\n<h3>Console Output</h3>\n<p><code>y Y1111</code></p>\n<p><code>x X000</code></p>\n<p>One thing I see people do a lot is use regex to replace values in a string. In python this is as easy as.</p>\n<pre><code class=\"language-python\">a = &#39;one two three&#39;\nprint a.replace(&#39;one&#39;, &#39;turtles&#39;)\nturles two three\n</code></pre>\n"
  },
  {
    "id": "blog:IOS-permissions",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-04-03T00:00:00.000Z",
    "title": "IOS Granular Permissions",
    "summary": "",
    "url": "/Blog/IOS-permissions/",
    "tags": [
      "IOS",
      "Cisco",
      "IAM"
    ],
    "content_html": "<p>If you have tiered levels of administrators, or you want to create an account for automation purposes best practice is to define a custom security level in IOS.</p>\n<!--more-->\n\n<p>Levels 1 and 15 are defined by default.</p>\n<h3>Allowing lower levels to see your configuration: IOS</h3>\n<pre><code class=\"language-plaintext\">conf t\nusername backup privilege 3 secret &lt;SECRET&gt;\nprivilege exec level 3 show startup-config\nprivilege exec level 3 show\nwr mem\n</code></pre>\n<h3>Allowing lower levels to see your configuration: FreeRADIUS:</h3>\n<blockquote>\n<p>/etc/freeradius/users</p>\n</blockquote>\n<pre><code class=\"language-plaintext\">backup\n    Service-Type = NAS-Prompt-User,\n    cisco-avpair = &quot;shell:priv-lvl=3&quot;,\n    Auth-Type = System,\n</code></pre>\n<h3>Defining the next user tier for NAT information: IOS</h3>\n<pre><code class=\"language-plaintext\">conf t\nusername natinfo privilege 4 secret &lt;SECRET&gt;\nprivilege exec level 4 show nat64 statistics\nwr mem\n</code></pre>\n<h3>Defining the next user tier for NAT information: FreeRADIUS</h3>\n<pre><code class=\"language-plaintext\">natinfo\n    Service-Type = NAS-Prompt-User,\n    cisco-avpair = &quot;shell:priv-lvl=4&quot;,\n    Auth-Type = System,\n</code></pre>\n<h3>Notes</h3>\n<ul>\n<li>Permissions stack up which means a user at Level 4 can also issue &#39;show startup-configuration&#39;</li>\n<li><code>show running-config</code> command does not work in this way for the IOS devices I have tried.</li>\n</ul>\n"
  },
  {
    "id": "blog:kvm-virsh-halt",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-04-10T00:00:00.000Z",
    "title": "Halting a KVM guest with virsh",
    "summary": "",
    "url": "/Blog/kvm-virsh-halt/",
    "tags": [
      "KVM",
      "Linux",
      "virsh"
    ],
    "content_html": "<p>KVM is great but I&#39;m making a note so I remember because this command gives me pause every time.  When a new VM has no OS or doesn&#39;t make it past the bootloader it appears to be non-responsive for the graceful shutdown command.</p>\n<h3>Sometimes <code>shutdown</code> in the virtual shell for KVM fails.</h3>\n<pre><code class=\"language-plaintext\">virsh # shutdown myvm\nDomain myvm is being shutdown\n</code></pre>\n<h4>But...</h4>\n<pre><code>114 myvm            running\n</code></pre>\n<p>In order to shutdown this host I use the &#39;destroy&#39; command. Destroy does not remove any files or otherwise permanently change the host data. Which for me, is unintuitive. It does remove it from the list of hosts shown with the &#39;list&#39; command. Destroy is like pulling the plug.</p>\n<blockquote>\n<p>virsh #destroy myvm</p>\n</blockquote>\n<p>The command that does what I would expect destroy to do is: &#39;undefine&#39;.</p>\n"
  },
  {
    "id": "blog:Beginning-BGP",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-04-16T00:00:00.000Z",
    "title": "Beginning BGP",
    "summary": "",
    "url": "/Blog/Beginning-BGP/",
    "tags": [
      "BGP",
      "Cisco"
    ],
    "content_html": "<p>I remember hearing a lot of conflicting information about BGP when I first started doing network admin stuff. A lot of time BGP is part of an HA strategy and there are people making business decisions surrounding the protocol itself. This breakdown strives to be accurate and laymen without being misleading.</p>\n<p>Specific misconceptions:</p>\n<ol>\n<li><p>You need a full time admin doing only BGP stuff.</p>\n</li>\n<li><p>You can accidentally take down the Internet if you mess up.</p>\n</li>\n<li><p>BGP is hard.</p>\n</li>\n</ol>\n<p>You do not need a &#39;full time&#39; person thinking about BGP around the clock, although you do need designated contacts for just-in-case scenarios. If your providers are handling their own business you don&#39;t have to worry about taking down the Internet. (Although some small version of this happened to YouTube <a href=\"http://www.macworld.com/article/1132256/networking.html\">http://www.macworld.com/article/1132256/networking.html</a>). BGP is no harder or easier than anything else. I have seen configurations that boggle the mind work for years. Correctly administered BGP does involves some savy.</p>\n<h3>What is BGP?</h3>\n<p>Usually referring to the current version 4. Just read it: <a href=\"https://en.wikipedia.org/wiki/Border_Gateway_Protocol\">https://en.wikipedia.org/wiki/Border_Gateway_Protocol</a></p>\n<h3>Seriously, What is BGP for though?</h3>\n<p>In order to have a service (or anything) available on the Internet it needs to be announced. Usually, your Internet Provider does this announcing for you. If you want to be the master of your own destiny you need to announce yourself. Literally, you say “here I am” to your provider. Your provider talks to other providers and before long everyone knows how to find you. When a user connects to their Internet provider they send a request for your service. Since you have made yourself known they can find you</p>\n<p>BGP is how we find groups of addressed devices on the Internet.</p>\n<h3>How can I start announcing myself?</h3>\n<p>In order to announce that you exist you need to have IP addresses. It&#39;s a non-human way for tracking down a resource; think phone numbers. The gentlemen at ARIN keep a big list of addresses in use. If you want to use BGP; you need addressing. If you want addressing; you talk to ARIN. There are two simultaneous IP address pools. The old is IPv4 and we are scraping the bottom of the bucket. That bucket was large enough to get the Internet this far (4 Billion+ addresses with a large chunk carved out for special reservations). The second bucket is called IPv6. IPv6 is a much deeper bucket, 3.4 x 10 to the 38th power. That is far, far, far more addresses than IPv4 has available. IPv6 has addresses reserved already for the Moon. Seriously.</p>\n<p>To get addresses you apply. It&#39;s that simple. <a href=\"https://www.arin.net/resources/request.html\">https://www.arin.net/resources/request.html</a></p>\n<h3>…almost that simple.</h3>\n<p>IPv4 is a dwindling resource. But it has been one for a long time. In my experience, getting an IPv6 block is very easy. Getting an IPv4 block requires more justification. Scarce resources are more valued. Without a block of my own addresses can I use BGP? Well, maybe. Some providers will allocate you a block of addresses from their pool. You don&#39;t own them. You may be able to advertise them out another provider if both providers agree that is reasonable. BGP is all about relationships. No provider has to allow you to announce your block on their network whether it has been issued to you or them. Thankfully providers are in the business of making money, and the only way to make money for them is to move traffic. If you can get an address block of your very own it is called Provider Independent Address Space. Meaning you can take your addresses and move to any provider that will have you. If you talk a provider into allocating you a block of addresses it is called Provider Dependent Address Space. In order to change providers you have to change IP blocks. It can be done.</p>\n<h3>Understanding Addressing</h3>\n<p>All address space given out is public information.</p>\n<p>Yahoo: <a href=\"http://whois.arin.net/rest/customer/C00146168\">http://whois.arin.net/rest/customer/C00146168</a>\nMozilla: <a href=\"http://whois.arin.net/rest/customer/C01111858\">http://whois.arin.net/rest/customer/C01111858</a></p>\n<h3>Wait…They want my ASN?</h3>\n<p>ASN is automomous system number. It is both a technical and a nontechnical entity. In a non-technical sense it is a number assigned to networks under a singular control. Some companies have multiple ASN&#39;s, but in general you join ARIN and you get an ASN. This ASN is unique to you, and it is how providers will know you.</p>\n<p>BGP thinks in ASN&#39;s.</p>\n<p>It&#39;s like this: You have a 1:1 relationship with your ASN, but a one-to-many relationship with your addressing space.</p>\n<p>Sort of like: You have a 1:1 relationship with your house address, but a one-to-many relationship for your house address\nto phone numbers associated with your address.</p>\n<p>Just Read it: <a href=\"http://en.wikipedia.org/wiki/Autonomous_System_(Internet)\">http://en.wikipedia.org/wiki/Autonomous_System_(Internet)</a></p>\n<h3>Why ASN&#39;s AND IP addresses?</h3>\n<p>When providers talk BGP to each other they refer to you and themselves by ASN number. That&#39;s the short version.</p>\n<p>BGP is a routing protocol. Most routing protocols rely on an addressing hierarchy. Therefore it&#39;s easy to follow the numbers and find your destination. If two roomates live in a house together and use the network 192.168.0.0/16 and they link up with their neighbors who use 172.16.0.0/16. They can point routes at each other and communications happens. If one roomate in the first house wants his own subnet they can break things down. 192.168.0.0/16 becomes 192.168.0.0/24 (first roomate) AND 192.168.1.0/24 (second roomate). But their neighbors still only use 192.168.0.0/16 as it&#39;s &#39;good enough&#39; to get to their house, and their house router knows how to distinguish between their rooms.</p>\n<p>BGP exists on a larger playing field. 10.0.1.0/24 and 10.0.2.0/24 could be assigned to people or companies that have no relationship to each other. Addressing on the Internet is not assigned in a way that makes it contiguous.</p>\n<p>It would be like if the two roomates were still using 192.168.0.0/24 and 192.168.1.0/24 but had now moved to different addresses. We would need to find a way to associate their IP block with their new location. The location would be the ASN and the address block …would be the address block.</p>\n<p>So when two routers talk BGP to each other they say: ASN 1 has 192.168.0.0/24. ASN 2 has 192.168.1.0/24</p>\n<p>So if BGPRouter1 says this to BGPRouter2. BGPRouter1 has to be associated with an ASN too. Let&#39;s say BGPRouter1 has ASN 3. Now BGPRouter2 knows: when I need to get to ASN1 or ASN2 I send things to ASN3. Like, if I need to mail this letter to Les Sauvages, France the first step is getting it to France.</p>\n<h3>Summation</h3>\n<ul>\n<li>BGP is how people find each other on the Internet. Usually providers worry about it.</li>\n<li>BGP is complex, but the basics are very straight forward.</li>\n<li>BGP is fundamental to understanding the Internet.</li>\n<li>ASN&#39;s can be assigned by ARIN. All you need to do is join.</li>\n<li>Addressing can be assigned by ARIN. All you need to do is apply.</li>\n</ul>\n"
  },
  {
    "id": "blog:Beginning-BGP-Configuration",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-04-17T00:00:00.000Z",
    "title": "Beginning IOS BGP Configuration",
    "summary": "",
    "url": "/Blog/Beginning-BGP-Configuration/",
    "tags": [
      "Cisco",
      "BGP"
    ],
    "content_html": "<p>This configuration is Cisco based but JunOS isn&#39;t too far of a stretch in my experience.</p>\n<p>First off: you need your ASN. You need your address block. Your address block must be at least /24.</p>\n<p>A general rule of thumb for awhile has been 2 GB of memory per full BGP table. Sometimes more is required and sometimes significantly less. The table is still growing and 2 GB is my personal baseline required.</p>\n<h3>Aliases: you will learn to like them</h3>\n<pre><code class=\"language-plaintext\">alias exec sumbgp6 show bgp ipv6 unicast summary\nalias exec sumbgp show ip bgp summary\nalias exec sbgp show run | section bgp\n</code></pre>\n<h4>Basic BGP stanza</h4>\n<pre><code class=\"language-plaintext\">config t\nip bgp-community new-format\n!insert your ASN\nrouter bgp \n !your router id should be set explicitly\n bgp router-id \n no bgp fast-external-fallover\n !notify syslog of bgp changes\n bgp log-neighbor-changes\n bgp graceful-restart restart-time 120\n bgp graceful-restart stalepath-time 360\n bgp graceful-restart\n neighbor  remote-as \n neighbor  description \n neighbor  version 4\n neighbor  activate\n</code></pre>\n<h3>Our First BGP Summary</h3>\n<pre><code class=\"language-plaintext\">RTRME(config-router)####do sumbgp\nBGP router identifier , local AS number \nBGP table version is 464187, main routing table version 464187\n446501 network entries using 66082148 bytes of memory\n446501 path entries using 28576064 bytes of memory\n73561/73558 BGP path/bestpath attribute entries using 9415808 bytes of memory\n69308 BGP AS-PATH entries using 2555070 bytes of memory\n68 BGP community entries using 1904 bytes of memory\n0 BGP route-map cache entries using 0 bytes of memory\n0 BGP filter-list cache entries using 0 bytes of memory\nBGP using 106630994 total bytes of memory\nBGP activity 460823/1679 prefixes, 461759/2621 paths, scan interval 60 secs\n\nNeighbor        V           AS MsgRcvd MsgSent   TblVer  InQ OutQ Up/Down  State/PfxRcd\n  4         2914   79993      80   464166    0    0 01:11:19   446501\n</code></pre>\n<h3>BGP: Why you no work?</h3>\n<pre><code>RTRME(config-router)####do sh ip bgp neighbor  advertised-routes\n\nTotal number of prefixes 0\n</code></pre>\n<h3>To Advertise it: We need to know where it is</h3>\n<pre><code>RTRME(config)####sh ip bgp \n% Network not in table\n\nRTRME(config)####ip route   null 0 200\n\nRTRME(config)####do sh ip bgp \nBGP routing table entry for , version 464822\nPaths: (1 available, best ####1, table default)\nMultipath: eBGP\n  Not advertised to any peer\n  Refresh Epoch 1\n  Local\n    0.0.0.0 from 0.0.0.0 ()\n      Origin IGP, metric 0, localpref 100, weight 32768, valid, sourced, local, best\nRTRME(config)####\n</code></pre>\n<h3>Resetting BGP</h3>\n<p>This is very aggressive and will reset your peering status. Lookup soft in/out if you are alreadying using BGP in production.</p>\n<blockquote>\n<p>RTRME####clear ip bgp *</p>\n</blockquote>\n<h3>Things we know about our neighbor</h3>\n<p>What is their status?</p>\n<blockquote>\n<p>sh ip bgp neighbors</p>\n</blockquote>\n<p>What are we advertising to them?</p>\n<pre><code class=\"language-plaintext\">\nRTRME####sh ip bgp neighbors  advertised-routes \nBGP table version is 447010, local router ID is \nStatus codes: s suppressed, d damped, h history, * valid, &gt; best, i - internal,\n              r RIB-failure, S Stale, m multipath, b backup-path, x best-external, f RT-Filter, a additional-path\nOrigin codes: i - IGP, e - EGP, ? - incomplete\n\n   Network          Next Hop            Metric LocPrf Weight Path\n*&gt;      0.0.0.0                  0         32768 i\n\nTotal number of prefixes 1 \n</code></pre>\n<h3>References</h3>\n<p><a href=\"https://www.cisco.com/c/en/us/support/docs/ip/border-gateway-protocol-bgp/19345-bgp-noad.html\">Troubleshoot Border Gateway Protocol Routes that Do Not Advertise</a>\n<a href=\"https://lg.zayo.com/lg.cgi\">Zayo Looking Glass</a>\n<a href=\"https://www.cisco.com/c/en/us/support/docs/ip/border-gateway-protocol-bgp/16137-cond-adv.html\">Configure and Verify the BGP Conditional Advertisement Feature</a></p>\n"
  },
  {
    "id": "blog:Registrar-Hacked",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-05-09T00:00:00.000Z",
    "title": "deviantART Registrar Name.com Compromised",
    "summary": "",
    "url": "/Blog/Registrar-Hacked/",
    "tags": [
      "dA"
    ],
    "content_html": "<p>So name.com was hacked and deviantart.com was one of the credentials dumped from their DB.</p>\n<p>How do I know? <a href=\"https://news.ycombinator.com/item?id=5676311\">Name.com Tells Customers To Change Password Due To Breach</a></p>\n<p><img src=\"/assets/images/post/namecomhack.png\" alt=\"Name.com letter to customers on comprompise\"></p>\n<p>What&#39;s interesting is that we know our password and we know their hash of it now.</p>\n<p>Even though the site where it was posted has been taken down at this time.</p>\n<p><a href=\"https://news.ycombinator.com/item?id=5677739\"><img src=\"/assets/images/post/namecomhack-hn.png\" alt=\"coworker post\"></a></p>\n<p>Now we know for esure they were/are(?) storing our password using <a href=\"https://dev.mysql.com/doc/refman/4.1/en/encryption-functions.html#function_password\"><code>MySQL PASSWORD()</code></a></p>\n<p>No actual damage was done for us as this point. </p>\n<p>Damn, though, that sucks all around.</p>\n<hr>\n"
  },
  {
    "id": "blog:TimeMachine",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-05-16T00:00:00.000Z",
    "title": "Time Machine?",
    "summary": "",
    "url": "/Blog/TimeMachine/",
    "tags": [
      "time",
      "SRE"
    ],
    "content_html": "<blockquote>\n<p>SRE: “When does it need to be done?”</p>\n</blockquote>\n<blockquote>\n<p>PM: “Next week at the latest.”</p>\n</blockquote>\n<blockquote>\n<p>SRE: “OK, we spend from now to next week working on a time machine. If we had a time machine it would already be done.”</p>\n</blockquote>\n<blockquote>\n<p>PM: “How so?”</p>\n</blockquote>\n"
  },
  {
    "id": "blog:Syn-Flood-Test",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-05-29T00:00:00.000Z",
    "title": "Syn Flood Testing",
    "summary": "",
    "url": "/Blog/Syn-Flood-Test/",
    "tags": [
      "Security",
      "DDOS"
    ],
    "content_html": "<p>Launching a SYN flood.</p>\n<p>Everyone know DDOS attacks happen and of these SYN floods may be the simplest to organize for attackers. As a defender you don&#39;t want the first time you see this kind of traffic to be when you are under attack.</p>\n<p>Launching a SYN attack against yourself.</p>\n<ol>\n<li>You can learn some tools of the trade</li>\n<li>You can test the weakness of your services</li>\n<li>You can mitigate those weaknesses</li>\n</ol>\n<p>A tool that is simple to use is <a href=\"https://github.com/foreni-packages/t50\">t50</a></p>\n<h3>Launching a SYN Flood</h3>\n<blockquote>\n<p>./t50 <DEST_IP> --flood -S --turbo</p>\n</blockquote>\n<pre><code>entering in flood mode...\nactivating turbo...\nhit CTRL+C to break.\n...\nT50 5.4.1 successfully launched on May 28th 2013 13:09:24\n</code></pre>\n<h3>On the destination [NOTE: SYN Cookies are enabled]</h3>\n<h4>Traffic</h4>\n<pre><code>    tx eth0: 1168 b/s rx eth0: 528 b/s\n    tx eth0: 1056 b/s rx eth0: 9160 b/s\n    tx eth0: 8616 b/s rx eth0: 528 b/s\n    tx eth0: 4944 b/s rx eth0: 528 b/s\n\n        *syn flood starts**\n\n    tx eth0: 10 Mb/s rx eth0: 12 Mb/s\n    tx eth0: 36 Mb/s rx eth0: 43 Mb/s\n    tx eth0: 38 Mb/s rx eth0: 46 Mb/s\n    tx eth0: 39 Mb/s rx eth0: 47 Mb/s\n    tx eth0: 39 Mb/s rx eth0: 47 Mb/s\n</code></pre>\n<pre><code>    possible SYN flooding on port 5666. Sending cookies.\n    possible SYN flooding on port 5666. Sending cookies.\n</code></pre>\n<h4>Connection Table</h4>\n<pre><code class=\"language-plaintext\">   while true; do netstat -n -p TCP tcp | grep  SYN_RECV | wc -l &gt;&gt; /tmp/syn.log; sleep 2; done\n\n    0\n    5\n    6\n    3\n    2\n    ...\n    **syn flood**\n    ...\n    142\n    140\n    144\n    143\n    142\n    142\n    143\n    142\n    141\n    141\n    140\n    137\n    138\n    140\n    142\n    142\n    142\n    145\n    144\n</code></pre>\n<h4>Effect</h4>\n<ul>\n<li>Massive lag in responsiveness for CLI commands</li>\n<li>Simple web server with (python -m SimpleHTTPServer) crashed</li>\n<li>Top shows ksoftirqd/0 pegging CPU</li>\n</ul>\n<h3>Guidance on size of flood</h3>\n<pre><code class=\"language-plaintext\">./t50 &lt;target&gt; --threshold 10000 -S #4Mbps\n./t50 &lt;target&gt; --threshold 20000 -S #8Mbps\n./t50 &lt;target&gt; --threshold 40000 -S #16Mbps\n\n#more or less consisten 4Mbps flood\nfor i in {1..100}; do ./t50 &lt;target&gt; --threshold 10000 -S; sleep 3; done\n</code></pre>\n<h3>Reference</h3>\n<p><a href=\"https://github.com/foreni-packages/t50\">t50</a></p>\n"
  },
  {
    "id": "blog:Bash-Troubleshooting-Boilerplate",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-05-30T00:00:00.000Z",
    "title": "Bash Troubleshooting Boilerplate",
    "summary": "",
    "url": "/Blog/Bash-Troubleshooting-Boilerplate/",
    "tags": [
      "Bash",
      "Linux"
    ],
    "content_html": "<p>I have a bash script that is being called multiple times instead of once.  I need to track down where it is being called from.</p>\n<p>Boiler plate that is nice for troubleshooting</p>\n<pre><code class=\"language-bash\">function trouble {\n    echo &quot;--------------------&quot;\n    date\n    echo &quot;whoami: $(whoami)&quot;\n    echo &quot;userid: $(id -u)&quot;\n    echo &quot;My pid is $$&quot;\n    echo &quot;working dir: $(pwd)&quot;\n    echo &quot;Called as: $0&quot;\n    echo &quot;Arguments: $@&quot;\n    echo &quot;user_pstree_begin&quot;\n    pstree $(whoami) -l\n    echo &quot;user_pstree_end&quot;\n    echo &quot;pid_pstree_begin&quot;\n    pstree -np $$\n    echo &quot;pid_pstree_end&quot;\n    echo &quot;--------------------&quot;\n}\n\nset -x\nepochtime=$(date +%s)\nfile=&quot;/tmp/debug-$epochtime.log&quot;\nlogger &quot;Creating: $file&quot;\ntrouble &gt; $file\n</code></pre>\n<h3>Looks like</h3>\n<pre><code class=\"language-plaintext\">\n@:~# cat /tmp/debug-1369940847.log \n--------------------\nThu May 30 12:07:27 PDT 2013\nwhoami: \nuserid: 0\nMy pid is 19891\nps_tree_begin\ntest.sh(19891)---pstree(19896)\nps_tree_end\nworking dir: /home/\nCalled as: ./test.sh\nArguments: \n--------------------\n@:~# \n</code></pre>\n<p>Syslog: <code>&lt;host&gt; &lt;me&gt;: Creating: /tmp/debug-1369940847.log</code></p>\n<p>This is especially helpful for cron jobs or background scripts.</p>\n"
  },
  {
    "id": "blog:Using-SNORT-on-PCAP",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-06-03T00:00:00.000Z",
    "title": "Using Snort on a PCAP file",
    "summary": "",
    "url": "/Blog/Using-SNORT-on-PCAP/",
    "tags": [
      "Security",
      "Snort",
      "PCAP"
    ],
    "content_html": "<p>Grabbing tcpdump output during a crisis can be hard to remember. Ideally, snort is running as as service inline or at least continually. Sometimes things happen outside of Snort&#39;s purview or you are testing what Snort picks ups.</p>\n<h3>Install tools</h3>\n<blockquote>\n<p>aptitude install snort snort-rules</p>\n</blockquote>\n<h3>Capture your traffic</h3>\n<blockquote>\n<p>sudo tcpdump -w test</p>\n</blockquote>\n<h3>Generate snort report</h3>\n<blockquote>\n<p>snort -r test -c /etc/snort/snort.conf -l .</p>\n</blockquote>\n<pre><code class=\"language-plaintext\">[**] [1:485:4] ICMP Destination Unreachable Communication Administratively Prohibited [**]\n[Classification: Misc activity] [Priority: 3] \n05/19-01:23:00.201765 74.76.148.114 -&gt; &lt;my_ext_ip&gt;\nICMP TTL:241 TOS:0x0 ID:32480 IpLen:20 DgmLen:56\nType:3  Code:13  DESTINATION UNREACHABLE: ADMINISTRATIVELY PROHIBITED,\nPACKET FILTERED\n** ORIGINAL DATAGRAM DUMP:\n&lt;my_ext_ip&gt;:80 -&gt; 74.76.148.114:25657\nTCP TTL:47 TOS:0x0 ID:22893 IpLen:20 DgmLen:44\nSeq: 0x654B5258\n** END OF DUMP\n</code></pre>\n<p>You can edit your <code>snort.conf</code> for what kinds of signatures to look for. ICMP can be a good indicator of shenanigans but is also very noisy.</p>\n"
  },
  {
    "id": "blog:Simple-Site-Loadtesting",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-06-25T00:00:00.000Z",
    "title": "Simple Site Loadtesting",
    "summary": "",
    "url": "/Blog/Simple-Site-Loadtesting/",
    "tags": [
      "Security"
    ],
    "content_html": "<p>Throwing some load at your setup and seeing how it reacts.</p>\n<p>There is a difference between problem solving, and solving problems <em>at scale</em>.</p>\n<h3>On your user host</h3>\n<blockquote>\n<p>aptitude install httping seige apache2 bc</p>\n</blockquote>\n<h3>On your webserver</h3>\n<blockquote>\n<p>aptitude install htop</p>\n</blockquote>\n<p>Seige is a lowkey load test tool, httping is nice for measuring response times in a consistent way while load testing, and apache is because we want the apache benchmark tool or &#39;ab&#39;.</p>\n<h3>Trying Seige</h3>\n<h4>Launching a test with seige: 3 concurrent users with 3 connections</h4>\n<blockquote>\n<p>siege -b -c 3 -r 3 <webserver>:80</p>\n</blockquote>\n<pre><code class=\"language-plaintext\">** SIEGE 2.70\n** Preparing 3 concurrent users for battle.\nThe server is now under siege...\nHTTP/1.1 200   0.01 secs:     146 bytes ==&gt; /\nHTTP/1.1 200   0.01 secs:     146 bytes ==&gt; /\nHTTP/1.1 200   0.01 secs:     146 bytes ==&gt; /\nHTTP/1.1 200   0.00 secs:     146 bytes ==&gt; /\nHTTP/1.1 200   0.00 secs:     146 bytes ==&gt; /\nHTTP/1.1 200   0.00 secs:     146 bytes ==&gt; /\nHTTP/1.1 200   0.00 secs:     146 bytes ==&gt; /\nHTTP/1.1 200   0.00 secs:     146 bytes ==&gt; /\nHTTP/1.1 200   0.00 secs:     146 bytes ==&gt; /\ndone.\nTransactions:                  9 hits\nAvailability:             100.00 %\nElapsed time:               0.01 secs\nData transferred:           0.00 MB\nResponse time:              0.00 secs\nTransaction rate:         900.00 trans/sec\nThroughput:             0.13 MB/sec\nConcurrency:                3.00\nSuccessful transactions:           9\nFailed transactions:               0\nLongest transaction:            0.01\nShortest transaction:           0.00\n</code></pre>\n<p>This is not a great indicator of performance under load. When I raise it to 3000 users at 10 requests I start seeing:</p>\n<p><code>descriptor table full sock.c:108: Too many open files</code></p>\n<p>So I raise the descriptor limit.</p>\n<blockquote>\n<p>cat /proc/sys/fs/file-max</p>\n</blockquote>\n<p>You can see your limits using</p>\n<blockquote>\n<p>ulimit -Sn\nulimit -Hn</p>\n</blockquote>\n<p>Now I see too much of:</p>\n<pre><code class=\"language-plaintext\">socket: connection timed out\n[error] socket: unable to connect sock.c:222: Operation already in progress\n</code></pre>\n<p>So I&#39;m not too happy with seige. For some tests it seems ok. For large test pools it hasn&#39;t won me over. Then again the launching host isn&#39;t that great so maybe it&#39;s on my side.</p>\n<p>A good compromise I found was</p>\n<blockquote>\n<p>siege -b -c 1000 -r 3 <webserver>:80</p>\n</blockquote>\n<h3>Trying ab.</h3>\n<p>A thousand concurrent threads with a thousand requests.</p>\n<blockquote>\n<p>ab -n 1000 -c 1000 http://<webserver>/</p>\n</blockquote>\n<pre><code class=\"language-plaintext\">This is ApacheBench, Version 2.3 &lt;$Revision: 655654 $&gt;\nCopyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\nLicensed to The Apache Software Foundation, http://www.apache.org/\n\nBenchmarking  (be patient)\nCompleted 100 requests\nCompleted 200 requests\nCompleted 300 requests\nCompleted 400 requests\nCompleted 500 requests\nCompleted 600 requests\nCompleted 700 requests\nCompleted 800 requests\nCompleted 900 requests\nCompleted 1000 requests\nFinished 1000 requests\n\n\nServer Software:        Apache/2.2.16\nServer Hostname:        \nServer Port:            80\n\nDocument Path:          /\nDocument Length:        177 bytes\n\nConcurrency Level:      1000\nTime taken for tests:   0.656 seconds\nComplete requests:      1000\nFailed requests:        0\nWrite errors:           0\nTotal transferred:      453000 bytes\nHTML transferred:       177000 bytes\nRequests per second:    1523.82 [#/sec] (mean)\nTime per request:       656.246 [ms] (mean)\nTime per request:       0.656 [ms] (mean, across all concurrent requests)\nTransfer rate:          674.11 [Kbytes/sec] received\n\nConnection Times (ms)\n              min  mean[+/-sd] median   max\nConnect:       11   15   2.9     15      21\nProcessing:     6  158 209.8     32     631\nWaiting:        5  158 209.9     32     631\nTotal:         20  174 210.7     53     646\n\nPercentage of the requests served within a certain time (ms)\n  50%     53\n  66%    234\n  75%    237\n  80%    238\n  90%    642\n  95%    645\n  98%    646\n  99%    646\n 100%    646 (longest request)\n</code></pre>\n<p>ab gives great data, and can generate a lot of load with minimal impact on the launching system.</p>\n<p>I eventually settled on <code>ab -k -n 2000000 -c 50 http://&lt;webserver&gt;/</code></p>\n<p>Use http-keepalive (for consistency with production) at 2 million requests making 50 simultaneously. These numbers were hitting a load of 8+ on my test server. Anything averaging over 3.5 in production would be flagged to look at, but load testing is all about pushing limits.</p>\n<p>Getting macro numbers from ab. Run your tests a lot and look at overall numbers.</p>\n<blockquote>\n<p>for i in {1..3}; do ab -n 1000 -c 1000 http://<webserver>/ &gt;&gt; test.txt; done</p>\n</blockquote>\n<p>What is the average response time for request in the 95th percentile?</p>\n<blockquote>\n<p>grep 95% test.txt | awk &#39;{total = total + $2}END{print total}&#39; </p>\n</blockquote>\n<p><code>4556 #&lt;-- total number</code></p>\n<p>I know I made 3 passes so my average 95th percentile response is <code>echo &quot;4556 / 3&quot; | bc</code> = <code>1518 (ms)</code></p>\n<p>This number is of limited value but adding your 95% through 100% and figuring out what your response times are for 95th perctile and above can be useful.</p>\n<blockquote>\n<p>grep -A 3 95% test.txt | awk &#39;{total = total + $2}END{print total}&#39;</p>\n</blockquote>\n<h3>Using httping</h3>\n<p>I like using httping in the background or on another host as a consistent measure of my response times.</p>\n<blockquote>\n<p>httping -c 10 <webserver> </p>\n</blockquote>\n<p>This makes 10 requests that look like:</p>\n<pre><code class=\"language-plaintext\">connected to &lt;webserver&gt;:80, seq=0 time=0.97 ms \n</code></pre>\n<p>I like to flood the host with requests:</p>\n<blockquote>\n<p>httping <webserver>  -f</p>\n</blockquote>\n"
  },
  {
    "id": "blog:SUP-devopskc",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2013-09-26T00:00:00.000Z",
    "title": "SUP Intro DevOpsKC",
    "summary": "",
    "url": "/Blog/SUP-devopskc/",
    "tags": [
      "SUP",
      "devops"
    ],
    "content_html": "<p>I walked through these slides demonstrating the simple tool <a href=\"https://github.com/chasemp/sup\">sup.py</a> I wrote at the <a href=\"https://www.meetup.com/DevOps-Kansas-City/\">devops kc meetup</a>. Sup can be used in place of ping/tcping/httping on some occasions to great/medium/some success!</p>\n<div id=\"html\" markdown=\"0\">\n<p><center><iframe src=\"http://www.slideshare.net/slideshow/embed_code/26585437\" width=\"476\" height=\"400\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe></center></p>\n</div>\n"
  },
  {
    "id": "blog:Python-Diamon-Statsd",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2014-02-07T00:00:00.000Z",
    "title": "Python monitoring end-to-end with Diamond, Statsd and Graphite",
    "summary": "",
    "url": "/Blog/Python-Diamon-Statsd/",
    "tags": [
      "Python",
      "Statsd",
      "Graphite"
    ],
    "content_html": "<p>If you stayed late at the DevOpsKC meetup last night you have may have caught me giving this talk about getting a monitoring system going using python from end-to-end. The meet was at offices of codero who were gracious hosts, and the food was provided by Cerner. Thanks again to the folks put this stuff together.</p>\n<div id=\"html\" markdown=\"0\">\n<p><center><iframe src=\"http://www.slideshare.net/slideshow/embed_code/31729631\" width=\"476\" height=\"400\" frameborder=\"0\" marginwidth=\"0\" marginheight=\"0\" scrolling=\"no\"></iframe></center></p>\n</div>\n\n\n<h3>References</h3>\n<p><a href=\"/assets/slides/python_and_trending_data_ops.pdf\">slides</a></p>\n"
  },
  {
    "id": "blog:Asking-for-help",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2015-04-08T00:00:00.000Z",
    "title": "Seeking Help On The Internet",
    "summary": "",
    "url": "/Blog/Asking-for-help/",
    "tags": [
      "Internet",
      "Security"
    ],
    "content_html": "<p>Getting help and soliciting feedback on the Internet essential reading:</p>\n<p>Great presentation directed at tech folks from India primarily looking to enter into an Open Source mentor relationship</p>\n<p><a href=\"http://www.shakthimaan.com/downloads/glv/presentations/i-want-2-do-project-tell-me-wat-2-do.pdf\">i-want-2-do-project-tell-me-wat-2-do</a></p>\n<p><a href=\"https://gitlab.wikimedia.org/epicpupper/phabricator/-/blob/T343258calEvents/src/docs/flavor/please_please_please.diviner\">please please please</a></p>\n<p><a href=\"http://www.catb.org/%7Eesr/faqs/smart-questions.html\">How to ask questions the smart way</a></p>\n"
  },
  {
    "id": "blog:post-mortem-archive",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2015-08-13T00:00:00.000Z",
    "title": "Post Mortem Archive",
    "summary": "",
    "url": "/Blog/post-mortem-archive/",
    "tags": [
      "Incident Response",
      "Security"
    ],
    "content_html": "<p>A resource maintained by the fabulous <a href=\"https://danluu.com/postmortem-lessons/\">Dan Luu</a></p>\n"
  },
  {
    "id": "blog:specialty-packet-capture",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2015-09-10T00:00:00.000Z",
    "title": "Specialty Packet Capture",
    "summary": "",
    "url": "/Blog/specialty-packet-capture/",
    "tags": [
      "standard"
    ],
    "content_html": "<p>Situations where it&#39;s useful to analyze traffic:</p>\n<ul>\n<li>Don&#39;t have access to the logs</li>\n<li>Want to look at traffic somewhere upstream like an LB</li>\n<li>Something is making logs ineffectual</li>\n<li>Other</li>\n</ul>\n<p>Pretty much all roads point to packet sniffing.</p>\n<h2>HTTPRY</h2>\n<p>An efficient packet sniffer aimed at HTTP</p>\n<p>No args output (as oneline but broken down for explanation):</p>\n<pre><code>    2015-10-09 17:46:48         - timestamp\n    10.0.0.1    10.0.0.2        - source-ip/dest-ip or vice versa (depending on arrow)\n    &gt;                   - direction of traffic\n    GET                 - http method\n    foo.com             - http host\n    /myuri              - the URI in question\n    HTTP/1.1                - HTTP version\n    -                   - status code\n    -                   - reason\n</code></pre>\n<p>The output fields are configurable. Say you only serve one site on a box so the host field never changes and the objective is to narrow down a few suspect URI&#39;s.</p>\n<blockquote>\n<p>httpry -f timestamp,source-ip,direction,request-uri</p>\n</blockquote>\n<pre><code>2015-10-09     18:10:43 10.0.0.1    &gt;   /myuri\n</code></pre>\n<p>Since httpry outputs text</p>\n<blockquote>\n<p>httpry -f timestamp,source-ip,request-uri | egrep -i &#39;/myuri/[0-9]&#39;{6}</p>\n</blockquote>\n<p>Other than text munging there are a few native mechanisms for targeting with tcpdump style filters</p>\n<blockquote>\n<p>httpry &#39;host 74.1.1.1 and port 8080&#39;</p>\n</blockquote>\n<p>specifying an HTTP method for collection (along with ability to read/write PCAP)</p>\n<blockquote>\n<p>httpry -m GET,POST</p>\n</blockquote>\n<p>There is also a native statistics mode in <code>httpry -s</code> that by provides meta stats.</p>\n<pre><code class=\"language-plaintext\">2015-10-09 19:20:48 one.myhost.org     147 rps\n2015-10-09 19:20:48 two.myhost.org     2 rps\n2015-10-09 19:20:48 three.myhost.org   9 rps\n2015-10-09 19:20:48 totals  156.46 rps\n</code></pre>\n<p>Show me data aggregated in 30s buckets with a minimum treshold of 10/rps</p>\n<blockquote>\n<p>httpry -s -l 10 -t 30 </p>\n</blockquote>\n<p><code>httpry</code> has the ability to run as a daemon natively as well.</p>\n<h2>ngrep</h2>\n<p>Payload aware network search tool with grep and tcpdump like magic</p>\n<blockquote>\n<p>ngrep port 80 -W single</p>\n</blockquote>\n<pre><code class=\"language-plaintext\">T 10.0.0.1:80 -&gt; 10.0.0.2:65227 [AP] HTTP/1.1 200 OK..\\\nDate: Fri, 09 Oct 2015 21:45:16 GMT..\\\nServer: Apache..Strict-Transport-Security: max-age=31536000..\\\nX-Powered-By: PHP/5.5.9-1ubuntu4.13..X-Frame-Options: Deny..\\\nCache-Control: private, no-cache, no-store, must-revalidate..\nPragma: no-cache..\\\nX-Content-Type-Options: nosniff..\\\nContent-Length: 49..Connection: close..Content-Type: application/json....\\\n{&quot;result&quot;:[],&quot;error_code&quot;:null,&quot;error_info&quot;:null}\n</code></pre>\n<p>So what if we are behind a reverse proxy and the header source IP address is only part of the story. Most likely we want to analyze the X-Forwarded-For field.</p>\n<p>Sample our web traffic honoring embedded linefeeds (newline) looking for X-forwarded-for header fields, extracting the initial IP value, and showing the top 10 IP&#39;s.</p>\n<blockquote>\n<p>ngrep -n 1000 port 80 -W byline | grep -i x-forwarded-for | awk &#39;{print $2}&#39; | cut -d &#39;,&#39; -f 1 | sort | uniq -c | sort -n | tail -n 10</p>\n</blockquote>\n<p>Watching for mail the hard way: <code>ngrep &#39;vacation&#39; port 25</code></p>\n<pre><code class=\"language-plaintext\">T 2620::62748 -&gt; 2620::76:25 [A]\nReturn-Path: no-reply@mail.org..To: foo@mail.org..From: dude &lt;no-reply\n@dude.org&gt;..Reply-to: noway@mail.org..Subject: foo asked for vacation\n</code></pre>\n<p>ngrep is extremely powerful but is vulnerable to packet fragmentation.</p>\n<h2>netsniff-ng</h2>\n<p>A super efficient packet capture tool that is Pcap independent</p>\n<blockquote>\n<p>/usr/sbin/netsniff-ng</p>\n</blockquote>\n<pre><code class=\"language-plaintext\">&lt; 3 66 1444429202.367551\n [ Eth MAC (84:78:ac:5a:19:41 =&gt; f2:3c:91:6e:f6:f5), Proto (0x0800, IPv4) ]\n [ Vendor (Unknown =&gt; Unknown) ]\n [ IPv4 Addr (99.x.x.x =&gt; 74.x.x.x), Proto (6), TTL (53), TOS (0), Ver (4),\n   IHL (5), Tlen (52), ID (48089), Res (0), NoFrag (1), MoreFrag (0), FragOff (0), CS\n   um (0x0daf) is ok ]\n [ TCP Port (62403 =&gt; 22 (ssh)), SN (0xbb019f19), AN (0xf7b8096d), DataOff (8\n   ), Res (0), Flags (ACK ), Window (8189), CSum (0x33aa), UrgPtr (0) ]\n [ chr ....T...M..O ]\n [ hex  01 01 08 0a 54 d4 be f7 4d a3 f6 4f ]\n</code></pre>\n<p>netsniff-ng is interesting for a few reasons:</p>\n<ul>\n<li>It uses a zero-copy mechanism for packet capture (libpcap &gt;1.0 does now too)</li>\n<li>It doesn&#39;t need libpcap</li>\n<li>It can write to libpcap format really efficiently</li>\n</ul>\n<h3>References</h3>\n<p><a href=\"https://dumpsterventures.com/jason/httpry/\">HTTPRY</a></p>\n<p><a href=\"https://taosecurity.blogspot.com/2008/06/logging-web-traffic-with-httpry.html\">Tao Security HTTPRY</a></p>\n<p><a href=\"http://www.stearns.org/doc/ngrep-intro.current.html\">Intro to NGrep</a></p>\n<p><a href=\"https://github.com/netsniff-ng/netsniff-ng\">Netsniff-ng</a></p>\n"
  },
  {
    "id": "blog:cncf-cloud-native-security-whitepaper-10",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2020-11-18T00:00:00.000Z",
    "title": "CNCF Cloud Native Security Whitepaper (1.0)",
    "summary": "",
    "url": "/Blog/cncf-cloud-native-security-whitepaper-10/",
    "tags": [
      "Publications",
      "CNCF",
      "Cloud Native",
      "Security"
    ],
    "content_html": "<p>The CNCF Security Special Interest Group (SIG) has just released a new Cloud Native Security Whitepaper to help educate the community about best practices for securing cloud native deployments. The whitepaper intends to provide organizations and their technical leadership with a clear understanding of cloud native security, its incorporation in lifecycle processes, and considerations for determining the most appropriate application thereof.</p>\n<p><a href=\"https://github.com/cncf/sig-security/blob/master/security-whitepaper/CNCF_cloud-native-security-whitepaper-Nov2020.pdf\">Read the publication →</a></p>\n"
  },
  {
    "id": "blog:97-things-every-information-security-professional-should-know-its-not-about-the-tools",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2021-05-18T00:00:00.000Z",
    "title": "97 Things Every Information Security Professional Should Know -- It's Not About The Tools",
    "summary": "",
    "url": "/Blog/97-things-every-information-security-professional-should-know-its-not-about-the-tools/",
    "tags": [
      "Publications",
      "O'Reilly",
      "Security"
    ],
    "content_html": "<p>Essay in the 97 Things O&#39;Reilly series for Information Security professionals.  Topic is the importance of shared objectives between security and the business aligned with risk oriented decision making.</p>\n<p><a href=\"https://www.oreilly.com/library/view/97-things-every/9781098101381/#toc\">Read the publication →</a></p>\n"
  },
  {
    "id": "blog:technical-debt-analogies-and-meanderings",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2022-10-13T00:00:00.000Z",
    "title": "technical debt: analogies and meanderings",
    "summary": "",
    "url": "/Blog/technical-debt-analogies-and-meanderings/",
    "tags": [
      "LinkedIn"
    ],
    "content_html": "<p>I would like to talk about tech debt.</p>\n"
  },
  {
    "id": "blog:is-access-to-email-something-you-have",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2022-10-27T00:00:00.000Z",
    "title": "Is access to email \"something you have\"​?",
    "summary": "",
    "url": "/Blog/is-access-to-email-something-you-have/",
    "tags": [
      "LinkedIn"
    ],
    "content_html": "<p>Is it MFA when a one-time password is sent via an email you have no administrative influence over?</p>\n<p>I&#39;m looking at <a href=\"https://help.okta.com/en-us/Content/Topics/Security/mfa/email.htm#:~:text=The%20Email%20Authentication%20factor%20allows,%2Dtime%20password%20(OTP).\">Okta Email Authentication MFA</a>. In this thought exercise, access to the 3rd party email system is password based as far as I&#39;ll be able to discern. Requiring a one-time pin sent to that email seems more defensible as multiple layers of a single factor (something you know), rather than a second layer (something you have or something you are).</p>\n<p>Especially interesting is Okta has equated SMS/Voice/Email as <a href=\"https://help.okta.com/en-us/Content/Topics/Security/mfa/about-mfa.htm\">equivalents</a>, and describes MFA without mention of representation across multiple factors as:</p>\n<blockquote>\n<p>an added layer of security used to verify an end user&#39;s identity when they sign in to an application.</p>\n</blockquote>\n<p><img src=\"https://media.licdn.com/dms/image/v2/D5612AQH5z19JgTuLFg/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1666876174954?e=1762387200&v=beta&t=78D0blXQeWM4gqdqPNek4-KMcMSjubf85UYxEzAKG40\" alt=\"No alt text provided for this image\"></p>\n<p>SMS and Voice as &quot;something you have&quot; is arguably reasonable, but I can see where VOIP may invalidate that assumption.</p>\n<p>Can access to an email be &quot;something you have&quot;?</p>\n"
  },
  {
    "id": "blog:21-musings-from-incident-response-ir-in-my-career-in-infrastructure-and-security-operations",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2022-12-16T00:00:00.000Z",
    "title": "21 musings from incident response (IR) in my career in infrastructure and security operations",
    "summary": "",
    "url": "/Blog/21-musings-from-incident-response-ir-in-my-career-in-infrastructure-and-security-operations/",
    "tags": [
      "LinkedIn"
    ],
    "content_html": "<p>These are my personal anecdotal conclusions and I totally appreciate it may not line up with anyone else&#39;s. This is US centric, as that is my experience, and I learned IR “on the job” over a few decades.  YMMV.</p>\n<ol>\n<li>Operational and security incidents often begin the same way, and may have the same impacts. Sometimes the separation boils down to intent.  That means your infrastructure operations team and your security operations team have to agree on what escalation means, when it matters, and how to document an ongoing investigation.  </li>\n<li>Response to a malicious incident is extremely time consuming. For every hour an adversary spends in control of a sensitive asset your organization may need to commit 3-10x+ in response. This is quarantining, establishing severity, determining depth of compromise, narrative development, investigation, remediation, evidence management, briefing external/in-house counsel, customer notification, high touch marquee customer meetings, law enforcement liaison, and more.</li>\n<li>Hostile actors are just as likely to be in time zones and on schedules that are not your own.  This will suck. An all hands on deck approach is not sustainable because the responders will be burnt up in 10-12 hours. It takes preparation, discipline and clear leave for folks to stand down during portions so there are hands available when the incident goes real-time beyond initial responder capacity.</li>\n<li>Boundaries and self-care are of the utmost importance. That said, my personal experience is that cautious bystanders seem to be rarely held to account for inaction. When information is scarce and it looks like a blast radius may be large, self-preservation may tell someone not to associate themselves.  Do not be surprised when folks go dark during triage or show up once the dust is settling and the damage is clearer. An incident will highlight the toxic cultural elements of an organization where blame, scapegoating, and politics rule. Do your best to not take it personally and to maintain your own state of mind.</li>\n<li>If the impact is serious, expect to need external help. Incident response is not something most in-house information security teams do enough of to avoid common pitfalls. Your lawyer will consult other lawyer&#39;s. Your evidence collection will similarly benefit from the hand of experience. Plus, if you collect in real-time with an external forensics firm <em>they</em> can be the people who have to testify in court.  Waiting until you need this augmentation is too late.  </li>\n<li>Your organization may have a cybersecurity component to their insurance policy.  This is a reactive mitigation (not a preventative control) but this is one of many reasons that cybersecurity needs a seat at the executive table.  There are almost certainly provisions for notification on breach depending on scope and impact.  Insurance makes money by not paying out.  Blend these requirements into your tabletop exercises.</li>\n<li>Readiness is the word I typically use to describe the extent to which an organization is prepared to handle the technical, legal, PR, and communications challenges of a compromise. This is often the most deficient area of an otherwise mature ISMS. Table tops are essential. Documentation on expected communications and an incident commander role are essential. Designated storage for evidence is essential. It&#39;s difficult to staff and fund these elements in most organizations. Usually you do not know, until you know.</li>\n<li>Escalating to the authorities is not a solution for immediate impact. Local police seem not to have jurisdiction or incentive. Federal police have significant discretion in what they pursue. Federal agencies will take your report and you may never meaningfully hear from them again. It is not the role of law enforcement officers to make your organization whole. They pursue criminals and sometimes contribute to recovering losses or damages as a result, but it is not their primary function. This does not mean do not involve law enforcement. It means they most likely will not be of immediate tactical assistance.</li>\n<li>If you do end up on the phone with a three letter agency, walk out the narrative of your evidence through the lens of quantifying impact on U.S. citizens. Generally, that is the narrative of consequence.</li>\n<li>Information Security is a series of tradeoffs for short-term confidentiality. The odds are overwhelming that encryption today will be trivial to break at some point in the future. Don&#39;t get mired in absolutes because there are few. Making your services and data an impractical and unattractive target (attackers do cost:benefit analysis just like you) is the idea. No defense is hands-off permanent, and no defense is 100% effective. That by itself does not mean it&#39;s a bad idea. Real-time ad hoc incident response mitigation measures can suffer from committee syndrome. No idea is perfect and gridlock ensues, or you end up with holes in your rain boots so your toes can breathe. A collection of hurdles is almost always the most effective defense.</li>\n<li>Confusion to your enemies! I have used mod_sec and JS fingerprinting to throw targeted HTTP 500&#39;s for endpoints based on prior attack patterns. It was shockingly effective.  A significant talking point opposing these types of measures may sound something like &quot;if we block their known traits we won&#39;t be able to effectively track their behavior&quot; and &quot;that is so easy to overcome it won&#39;t do any good&quot;. Attacker&#39;s cannot be both so sophisticated they are immune to new costs introduced by changes in response tactics AND be so predictable in pattern that they are being reliably monitored. Defense is hard and fatalism is paralyzing. Defense is primarily about dissuasion rather than absolutes.</li>\n<li>You are more likely to be compromised through an ancillary and/or support service than your primary production endpoints. Financial reimbursement portals, ticketing systems, development platforms, B2B integrations, and data warehouses for BI (this is a pot of gold) are attractive targets. The primary &quot;production&quot; systems probably get basic controls and oversight. Tech on the periphery is often some degree of skunkworks passion project &#39;this isn&#39;t what I was hired for but...&#39;, that had to skirt policy and controls to get rolling.</li>\n<li>Many companies I have experience with have a pervasive internal story outlining why they are not an attractive target for a cybersecurity attack. I suspect this is partially a coping mechanism, subconscious avoidance and recency bias. It is one of the most pernicious forces working against readiness. FUD is not a counterpoint. A consistent reinforcement of how readiness contributes to resilience and why that matters for the bottom line is all you have. It may not be enough, but that&#39;s the voice which represents systemic change on the wide arc.</li>\n<li>During response to an incident, from declaration to close, it is vitally important to differentiate three categories of information: assumptions (you have them, you need them, they often must be explicitly acknowledged), opinions (what you think may be happening) and facts (what you can prove to be true). A big part of readiness is learning how to communicate in this way. &quot;How do we know that?&quot; Is the first question out of my mouth when new information lands</li>\n<li>Incident response is an order of magnitude more effective in high trust teams. Recreating a timeline with overlapping motive and intent is full of speculation. Too much and you will drown in noise, too little and you will stall out into hoping blindly it doesn&#39;t happen again.</li>\n<li>The most dreaded attacker is not necessarily the most technical. I have seen quite a few incidents where we found ourselves saying &quot;If they only knew to do x that would have been 10 times worse&quot;. The scariest adversary has knowledge of your processes and tools, patience, and enough technical acumen to bridge those assets together.</li>\n<li>Malicious actors make mistakes. Full stop. Check for the obvious: shell history, sent messages, deleted messages, archive files, tmp, ss (netstat), etc. If you assume every hostile actor is above reproach you won&#39;t get very far.</li>\n<li>Identifying an attacker with high confidence is very, very difficult. That said, everyone has the tools they use without thinking. Pattern identification is a part of defense. Think in terms of persona rather than identity.  You are mitigating vulnerabilities, not threats.</li>\n<li>If you are at it long enough, someone will ask you about &quot;hacking back&quot;. They mean attacking the attacker. They will ask in a f2f/video meeting. This is personal liability territory and you would do well to ask for the request in writing from legal. That won&#39;t happen. If it does happen, my advice is don&#39;t do it.</li>\n<li>There may be pressure to minimize, downplay, spin, and outright lie about impact (or cause). The more toxic the environment, the more likely and insidious the coercion. Integrity is tantamount to credibility.</li>\n<li>You cannot prove a negative, and so absence of evidence is absence of conclusion. But not necessarily absence of activity. It&#39;s the best we can do. &quot;No evidence of...&quot;. &quot;No indication of...&quot;. This becomes your language when breach and incident disclosure are part of your duties.</li>\n</ol>\n"
  },
  {
    "id": "blog:code-generation-and-open-source-stricture",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2023-01-12T00:00:00.000Z",
    "title": "Code generation and open source stricture.",
    "summary": "",
    "url": "/Blog/code-generation-and-open-source-stricture/",
    "tags": [
      "LinkedIn"
    ],
    "content_html": "<p>I&#39;m using a <a href=\"https://github.com/onelogin/onelogin-python-sdk\">Python library</a> that has a public repository and an <a href=\"https://opensource.org/licenses\">OSI</a> friendly license, but I cannot meaningfully contribute to the project to fix bugs I am encountering. This is fascinating and cumbersome. It&#39;s not unusual to find useful <a href=\"https://en.wikipedia.org/w/index.php?title=Free_and_open-source_software&redirect=yes\">FLOSS</a> code that is <a href=\"https://en.wikipedia.org/wiki/Abandonware\">abandonware</a>, but it is a relatively new phenomenon for the code itself to be programmatically generated.</p>\n<p>Enter <a href=\"https://openapi-generator.tech/\">OpenAPI Generator</a> (you are more likely to be familiar with <a href=\"https://swagger.io/blog/api-strategy/difference-between-swagger-and-openapi/\">Swagger</a>)</p>\n<p>Here&#39;s my understanding of the value proposition, you&#39;ve written a server with a <a href=\"https://en.wikipedia.org/wiki/Representational_state_transfer\">RESTful</a> API interface. Historically, it&#39;s been common practice to stub out some examples in documentation using <a href=\"https://curl.se/\">curl</a>. The mental leap to implementation of a client side library in a language of choice is fairly small, but it is not nonexistent. Folks come along and write idiomatic code to create a basic <a href=\"https://en.wikipedia.org/wiki/Software_development_kit\">SDK</a> in their preferred language (example: <a href=\"https://redis.io/\">Redis</a> client libraries for <a href=\"https://github.com/redis/redis-py\">Python</a>, <a href=\"https://github.com/redis/jedis\">Java</a>, and .<a href=\"https://github.com/redis/NRedisStack\">NET</a>). These language specific libraries can be of varying quality and completeness depending on the author, original needs, etc. Changes to how a server side endpoint behaves has to matriculate out to all the various client side libraries. It takes time, it&#39;s messy, and it&#39;s human maintenance.</p>\n<p>Queue the next evolution, you&#39;ve written a server with a RESTful API. You write a schema definition file that describes in declarative terms the semantics of the API. This <a href=\"https://yaml.org/\">YAML</a> file conforms to the <a href=\"https://spec.openapis.org/oas/v3.1.0\">OpenAPI Specification (OAS)</a>. Now you can run one of 60+ generators to create consistent client side libraries to allow consumption of your API resources without a human writing novel code for this purpose. When you update your YAML schema you can similarly regenerate your client side code in every language. This is amazing.</p>\n<p><a href=\"https://raw.githubusercontent.com/openapitools/openapi-generator/master/modules/openapi-generator/src/test/resources/3_0/petstore.yaml\">Example</a> of an OpenAPI YAML schema:</p>\n<p>openapi: 3.0\nservers:\n  - url: &#39;<a href=\"http://petstore.swagger.io/v2\">http://petstore.swagger.io/v2</a>&#39;\ninfo:\n  description: &gt;-\n    This is a sample server Petstore server. For this sample, you can use the api key\n    `special-key` to test the authorization filters.\n  version: 1.0.0\n  title: OpenAPI Petstore\n  license:\n    name: Apache-2.0\n    url: &#39;<a href=\"https://www.apache.org/licenses/LICENSE-2.0.html\">https://www.apache.org/licenses/LICENSE-2.0.html</a>&#39;\ntags:\n  - name: pet\n    description: Everything about your Pets\n  - name: store\n    description: Access to Petstore orders\n  - name: user\n    description: Operations about user\npaths:\n  /pet:\n    post:\n      tags:\n        - pet\n      summary: Add a new pet to the store\n      description: &#39;&#39;\n      operationId: addPet\n      responses:\n        &#39;200&#39;:\n          description: successful operation\n          content:\n            application/xml:\n              schema:\n                $ref: &#39;#/components/schemas/Pet&#39;\n            application/json:\n              schema:\n                $ref: &#39;#/components/schemas/Pet&#39;0\n...</p>\n<p>Now imagine you write the YAML schema first and the code for the server side endpoint is generated (or more likely has the structure stubbed out), the client side libraries are generated in 60 languages, and the documentation portal to inform humans on the use case and particulars of consumption are consistent and published alongside both. This is even more amazing.</p>\n<p>Even though this is a glimpse of the future (opinion) it is not a panacea. The end result server side behavior has to match in exactitude to the description in the schema used to generate downstream artifacts. If not, something will be broken. I am experiencing exactly this issue.</p>\n<p><a href=\"https://www.onelogin.com/\">Onelogin</a> is an identity and access management provider. I am attempting to use their <a href=\"https://github.com/onelogin/onelogin-python-sdk\">client library for Python</a> that is generated using the OpenAPI specification described above.</p>\n<p><a href=\"https://github.com/onelogin/onelogin-python-sdk/\"><img src=\"https://media.licdn.com/dms/image/v2/D5612AQFELQB8GKMFAA/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1673551169109?e=1762387200&v=beta&t=pX8pHPYq0cvGcHO6iBEb61t2HqqmC2YdHsY3dQVwMLs\" alt=\"No alt text provided for this image\"></a></p>\n<p>OpenAPI README header</p>\n<p>So, what is the bug?</p>\n<p>I believe I&#39;m seeing the same behavior in a few cases. Let&#39;s take the <a href=\"https://github.com/onelogin/onelogin-python-sdk#getting-started\">getting started code</a> for generating a token and combine it with the <a href=\"https://github.com/onelogin/onelogin-python-sdk/blob/master/docs/DefaultApi.md#get_user\">get_user</a> or the <a href=\"https://github.com/onelogin/onelogin-python-sdk/blob/master/docs/DefaultApi.md#list_users\">list_users(app_id)</a> example.</p>\n<p>...\nuser = api_instance.get_user(user_id_int)</p>\n<p>users = api_instance.list_users(app_id_int)\n...</p>\n<p>These can result in some version of the following:</p>\n<p>onelogin.exceptions.ApiTypeError: Invalid type for variable &#39;preferred_locale_code&#39;. Required value type is str and passed type was NoneType at [&#39;received_data&#39;][&#39;preferred_locale_code&#39;]</p>\n<p>onelogin.exceptions.ApiTypeError: Invalid type for variable &#39;locked_until&#39;. Required value type is str and passed type was NoneType at [&#39;received_data&#39;][&#39;locked_until&#39;]</p>\n<p>onelogin.exceptions.ApiTypeError: Invalid type for variable &#39;trusted_idp_id&#39;. Required value type is int and passed type was NoneType at [&#39;received_data&#39;][&#39;trusted_idp_id&#39;]</p>\n<p>This is a classic mismatch in expected behavior between a client and server.</p>\n<p>What seem to be happening is the client side code is including the full list of possible params in the query, but in cases where a value is not specified explicitly in the code <a href=\"https://www.w3schools.com/python/ref_keyword_none.asp\">None</a> is used as the value. The client is assuming with None being a <a href=\"https://www.pythonmorsels.com/truthiness/\">falsey</a> value it will be non-impacting. The server looks at the full request and recognizes parameters that are NoneType value but have another valid type required (int, str). It returns a status interpreted as an exception (error) by the client code. The server is assuming that any specified value is meaningful and seeking to validate adherence of expected object type.</p>\n<p>I can validate the server side is capable of fulfilling the request by using <a href=\"https://pypi.org/project/requests/\">python-requests</a> to make the same inquiries (including using the same generated token):</p>\n<p>import request</p>\n<p>class BearerAuth(requests.auth.AuthBase):\n    def __init__(self, token):\n        self.token = token\n    def __call__(self, r):\n        r.headers[&quot;authorization&quot;] = &quot;Bearer &quot; + self.token\n        return rs</p>\n<h1>Get users for APP <MYAPP> (int)</h1>\n<p>response = requests.get(&#39;<a href=\"https://api.us.onelogin.com/api/2/apps/\">https://api.us.onelogin.com/api/2/apps/</a><MYAPP>/users&#39;, auth=BearerAuth(token[&#39;access_token&#39;]))</p>\n<p>print(response.status_code)</p>\n<h1>Get details for user <MYUSER> (int)</h1>\n<p>user_details = requests.get(&#39;<a href=\"https://api.us.onelogin.com/api/2/users/\">https://api.us.onelogin.com/api/2/users/</a><MYUSER>&#39;, auth=BearerAuth(token[&#39;access_token&#39;]))</p>\n<p>print(user_details.status_code)</p>\n<p>Both queries return valid content and 200 status codes.</p>\n<p>At this point we have:</p>\n<ul>\n<li>Server side code we cannot see but which we can demonstrate functions using primitive requests</li>\n<li>Client side code that is generated by an OpenAPI schema licensed with <a href=\"https://github.com/onelogin/onelogin-python-sdk/blob/master/LICENSE\">MIT</a></li>\n<li>Client side behavior that is errant</li>\n</ul>\n<p>Normally I would attempt to diagnose and search for an existing known issue to discuss, and, if possible, open a <a href=\"https://docs.github.com/en/pull-requests/collaborating-with-pull-requests/incorporating-changes-from-a-pull-request/merging-a-pull-request\">pull request</a> to address. In this case, the code itself is generated. Fixing it in place is not very useful. Any fix will be overwritten with the next generated version. The only real fix is addressing the OpenAPI schema document or the server side validation that is conflicting.</p>\n<p>While I have the code and rights to it the OpenAPI schema is not included.</p>\n<p><strong>This project is open source but still a walled garden.</strong></p>\n<p>Interestingly, the project itself has been updated relatively recently.</p>\n<p><img src=\"https://media.licdn.com/dms/image/v2/D5612AQGAy5aAx3MukQ/article-inline_image-shrink_1000_1488/article-inline_image-shrink_1000_1488/0/1673552291803?e=1762387200&v=beta&t=796NJe7cVPvMhThohAFIXTslYLUglia5GmsARmqO9UU\" alt=\"No alt text provided for this image\"></p>\n<p>Updates happening for OneLogin Python SDK</p>\n<p>But issues seem to be stale with the last closed issue approximately a year ago.</p>\n<p><img src=\"https://media.licdn.com/dms/image/v2/D5612AQFlikv-HDaXlg/article-inline_image-shrink_1500_2232/article-inline_image-shrink_1500_2232/0/1673552399989?e=1762387200&v=beta&t=9JSiuFY2zqTyORGb65zssfuhoSpD1e2Xs7UW21m1obY\" alt=\"No alt text provided for this image\"></p>\n<p>Activity in issues for OneLogin Python SDK</p>\n<p>The last comment on an open issue is:</p>\n<p><a href=\"https://github.com/onelogin/onelogin-python-sdk/issues/70\"><img src=\"https://media.licdn.com/dms/image/v2/D5612AQEtQIkEAP4Wrw/article-inline_image-shrink_1000_1488/article-inline_image-shrink_1000_1488/0/1673552610769?e=1762387200&v=beta&t=Bur1sfQT4Fhw58Rk04K-Gu6PvVzRQjyFx5IN6OrW1yM\" alt=\"No alt text provided for this image\"></a></p>\n<p>OneLogin Python SDK issue #70 comment</p>\n<p>I&#39;m not writing this to take a shot at OneLogin. As the landscape of software development changes, there are interesting circumstances where the letter of the law and the intent of what it means to be open source may diverge. As humans create these technologies that allows us to be further removed from certain outcomes (a good thing), it seems we need to be careful about enabling the same social outcomes (a great thing) to preserve a collaborative future.</p>\n"
  },
  {
    "id": "blog:aivss-scoring-system-for-owasp-agentic-ai-core-security-risks-v05",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2025-07-28T00:00:00.000Z",
    "title": "AIVSS Scoring System For OWASP Agentic AI Core Security Risks v0.5",
    "summary": "",
    "url": "/Blog/aivss-scoring-system-for-owasp-agentic-ai-core-security-risks-v05/",
    "tags": [
      "Publications",
      "OWASP",
      "AI",
      "Security"
    ],
    "content_html": "<p>This foundational document introduces the OWASP AI Vulnerability Scoring System (AIVSS), a standardized framework for assessing and quantifying security risks in AI systems, with a specific focus on agentic AI architectures. Version 0.5 represents the initial release of our comprehensive scoring methodology.  Chase Pettet | Life360 | Key Contributor/Reviewer</p>\n<p><a href=\"https://aivss.owasp.org/\">Read the publication →</a></p>\n"
  },
  {
    "id": "blog:walden-pond",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2025-10-20T00:00:00.000Z",
    "title": "Walden Pond",
    "summary": "",
    "url": "/Blog/walden-pond/",
    "tags": [
      "Nature",
      "History",
      "Literature"
    ],
    "content_html": "<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/b/bc/Walden_Pond%2C_2010.jpg\" alt=\"Walden Pond, photographed in 2010\"></p>\n<p><a href=\"https://en.wikipedia.org/wiki/File:Walden_Pond,_2010.jpg\">Walden Pond</a> - A tranquil body of water in Concord, Massachusetts, made famous by Henry David Thoreau&#39;s 1854 book &quot;Walden; or, Life in the Woods.&quot; </p>\n<p>Thoreau lived in a small cabin near this pond for two years, two months, and two days, using his time there to reflect on simple living in natural surroundings. The experience became the basis for one of America&#39;s most influential works of literature and philosophy.</p>\n<p>Today, Walden Pond is a National Historic Landmark and a popular destination for those seeking connection with nature and literary history.</p>\n<hr>\n<p><em>Photo: <a href=\"https://commons.wikimedia.org/wiki/File:Walden_Pond,_2010.jpg\">Walden Pond, 2010</a> by <a href=\"https://www.flickr.com/people/31902638@N06\">ptwo</a> from Flickr, licensed under <a href=\"https://creativecommons.org/licenses/by/2.0/\">CC BY 2.0</a></em></p>\n"
  },
  {
    "id": "blog:giscus-comments-integration",
    "type": "blog",
    "source": "markdown",
    "timestamp": "2025-10-28T00:00:00.000Z",
    "title": "Giscus comments integration",
    "summary": "",
    "url": "/Blog/giscus-comments-integration/",
    "tags": [
      "Giscus",
      "Comments",
      "GitHub Discussions"
    ],
    "content_html": "<p>I added comment functionality to the timeline site using Giscus, a comments system powered by GitHub Discussions.</p>\n<h2>Why Giscus</h2>\n<p>Requirements for a comments system were simple: no database, minimal maintenance, and direct moderation within the existing workflow. Giscus fits these constraints by using GitHub Discussions as the backend. Comments appear on timeline items and blog posts, stored as GitHub Discussions and manageable within the repository.</p>\n<h2>Implementation</h2>\n<p>The integration has three components: global configuration, per-item control, and rendering.</p>\n<h3>Global Configuration</h3>\n<p>Comments can be disabled site-wide via <code>config.ts</code>:</p>\n<pre><code class=\"language-typescript\">export const config = {\n  commentsEnabled: true,\n} as const;\n</code></pre>\n<p>When set to false, comments are hidden everywhere. Individual items can still disable comments via hashtags.</p>\n<h3>Per-Item Control</h3>\n<p>Specific items can disable comments using the <code>#nocomments</code> or <code>#nc</code> hashtag. This works across content types:</p>\n<ul>\n<li>Blog posts: add the tag to markdown frontmatter</li>\n<li>Timeline items: add the hashtag in content text or as a tag</li>\n</ul>\n<h3>Rendering</h3>\n<p>For blog posts, Giscus loads with a pathname mapping strategy. Each post gets its own discussion thread. The script loads when the page loads and renders below the content.</p>\n<p>For timeline items, Giscus loads dynamically when opening an item. The script is removed when closing the panel to avoid conflicts. This keeps the timeline responsive.</p>\n<h2>Technical Details</h2>\n<h3>Configuration</h3>\n<p>Giscus connects to the <code>chasemp/timeline</code> repository with the category &quot;Ideas&quot; (category ID <code>DIC_kwDOQDOMbM4CxLZb</code>). The mapping strategy is &quot;specific&quot; for timeline items, using the item ID as the discussion term. Blog posts use pathname mapping.</p>\n<p>A custom theme in <code>giscus-custom.css</code> centers the sign-in button and positions it at the top of the comments section.</p>\n<h3>Error Handling</h3>\n<p>If Giscus fails to load, the comments section hides after a 10-second timeout. This prevents displaying empty sections and keeps the interface clean.</p>\n<h3>References</h3>\n<ul>\n<li><a href=\"https://giscus.app/\">Giscus documentation</a></li>\n<li><a href=\"https://docs.github.com/en/repositories/managing-your-repositorys-settings-and-features/enabling-features-for-your-repository/enabling-or-disabling-github-discussions-for-a-repository\">GitHub Discussions configuration</a></li>\n</ul>\n"
  }
]